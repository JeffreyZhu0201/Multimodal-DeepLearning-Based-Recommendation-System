{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f80a0f7",
   "metadata": {},
   "source": [
    "# Deep Learning Recommenddation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa87976",
   "metadata": {},
   "source": [
    "## 数据集准备\n",
    "基于Movie-Lens 32M数据集进行实验\n",
    "*ml-32m*\n",
    "* ml-32m/ratings.csv\n",
    "* ml-32m/movies.csv\n",
    "* ml-32m/tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83430a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ml-32m/ratings.csv\n",
    "userId,movieId,rating,timestamp\n",
    "1,17,4.0,944249077\n",
    "1,25,1.0,944250228\n",
    "1,29,2.0,943230976\n",
    "1,30,5.0,944249077\n",
    "# ml-32m/movies.csv\n",
    "movieId,title,genres\n",
    "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\n",
    "2,Jumanji (1995),Adventure|Children|Fantasy\n",
    "3,Grumpier Old Men (1995),Comedy|Romance\n",
    "4,Waiting to Exhale (1995),Comedy|Drama|Romance\n",
    "5,Father of the Bride Part II (1995),Comedy\n",
    "# ml-32m/tags.csv\n",
    "userId,movieId,tag,timestamp\n",
    "22,26479,Kevin Kline,1583038886\n",
    "22,79592,misogyny,1581476297\n",
    "22,247150,acrophobia,1622483469\n",
    "34,2174,music,1249808064\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ccfbef",
   "metadata": {},
   "source": [
    "## 基础NCF模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e266b52",
   "metadata": {},
   "source": [
    "#### 导入必要包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271cb8c",
   "metadata": {},
   "source": [
    "#### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb6d10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "ratings = pd.read_csv('../Dataset/ml-32m/ratings.csv')\n",
    "csv_file_path = 'loss_data.csv'\n",
    "print(\"数据读取成功\")\n",
    "# 创建用户和电影映射字典,将稀疏数据稠密化\n",
    "user_ids = ratings['userId'].unique()\n",
    "user_to_idx = {user: idx for idx, user in enumerate(user_ids)}\n",
    "movie_ids = ratings['movieId'].unique()\n",
    "movie_to_idx = {movie: idx for idx, movie in enumerate(movie_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为连续索引\n",
    "ratings['user_idx'] = ratings['userId'].map(user_to_idx)\n",
    "ratings['movie_idx'] = ratings['movieId'].map(movie_to_idx)\n",
    "# 归一化评分到0-1范围\n",
    "ratings['rating'] = ratings['rating'] / 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf291b",
   "metadata": {},
   "source": [
    "#### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ab3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6429e",
   "metadata": {},
   "source": [
    "#### 实现Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fdcffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Dataset类\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.users[idx], dtype=torch.long),\n",
    "            torch.tensor(self.movies[idx], dtype=torch.long),\n",
    "            torch.tensor(self.ratings[idx], dtype=torch.float)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202d1bb",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "batch_size = 2048\n",
    "\n",
    "train_dataset = MovieLensDataset(train_df['user_idx'].values, \n",
    "                               train_df['movie_idx'].values,\n",
    "                               train_df['rating'].values)\n",
    "val_dataset = MovieLensDataset(val_df['user_idx'].values,\n",
    "                             val_df['movie_idx'].values,\n",
    "                             val_df['rating'].values)\n",
    "test_dataset = MovieLensDataset(test_df['user_idx'].values,\n",
    "                              test_df['movie_idx'].values,\n",
    "                              test_df['rating'].values)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,pin_memory=True)\n",
    "print(\"数据加载成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c1ea6",
   "metadata": {},
   "source": [
    "#### 定义推荐模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义推荐模型\n",
    "class Recommender(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=32, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_emb = nn.Embedding(num_movies, embedding_dim)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, user, movie):\n",
    "        user_emb = self.user_emb(user)\n",
    "        movie_emb = self.movie_emb(movie)\n",
    "        x = torch.cat([user_emb, movie_emb], dim=1)\n",
    "        return self.fc(x).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54451cfa",
   "metadata": {},
   "source": [
    "#### 加载模型，指定优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 初始化模型和优化器\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "n_users = len(user_ids)\n",
    "n_movies = len(movie_ids)\n",
    "\n",
    "model = Recommender(n_users, n_movies).to(device)\n",
    "if os.path.exists('best_model.pth'):\n",
    "    model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "    print(\"已加载保存的模型参数\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de92bb8",
   "metadata": {},
   "source": [
    "#### 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True\n",
    ")\n",
    "# 验证集\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "# 测试集\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "loss_array = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1} Training'):\n",
    "        user, movie, rating = [x.to(device) for x in batch]\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user, movie)\n",
    "        loss = criterion(pred, rating)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * user.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f'Epoch {epoch+1} Validation'):\n",
    "            user, movie, rating = [x.to(device) for x in batch]\n",
    "            pred = model(user, movie)\n",
    "            val_loss += criterion(pred, rating).item() * user.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    loss_array.append([train_loss,val_loss])\n",
    "\n",
    "    print(f'Epoch {epoch+1}:')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    # 保存损失数据到CSV文件\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['train_loss', 'val_loss'])  # 添加表头\n",
    "        csv_writer.writerows(loss_array)\n",
    "\n",
    "print(\"训练完成，开始测试阶段\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582e321",
   "metadata": {},
   "source": [
    "#### 测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        user, movie, rating = [x.to(device) for x in batch]\n",
    "        pred = model(user, movie)\n",
    "        test_loss += criterion(pred, rating).item() * user.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "test_loss_csv = 'test_loss.csv'\n",
    "\n",
    "with open(test_loss_csv, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['test_loss'])  # 添加表头\n",
    "    csv_writer.writerow([test_loss])  # 写入测试损失\n",
    "\n",
    "print(loss_array)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test RMSE: {np.sqrt(test_loss * 5.0**2):.4f}')  # 反归一化后计算RMSE"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
