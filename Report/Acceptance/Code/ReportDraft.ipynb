{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f80a0f7",
   "metadata": {},
   "source": [
    "# Deep Learning Recommenddation System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa87976",
   "metadata": {},
   "source": [
    "## 数据集准备\n",
    "基于Movie-Lens 32M数据集进行实验\n",
    "*ml-32m*\n",
    "* ml-32m/ratings.csv\n",
    "* ml-32m/movies.csv\n",
    "* ml-32m/tags.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83430a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# ml-32m/ratings.csv\\nuserId,movieId,rating,timestamp\\n1,17,4.0,944249077\\n1,25,1.0,944250228\\n1,29,2.0,943230976\\n1,30,5.0,944249077\\n# ml-32m/movies.csv\\nmovieId,title,genres\\n1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\\n2,Jumanji (1995),Adventure|Children|Fantasy\\n3,Grumpier Old Men (1995),Comedy|Romance\\n4,Waiting to Exhale (1995),Comedy|Drama|Romance\\n5,Father of the Bride Part II (1995),Comedy\\n# ml-32m/tags.csv\\nuserId,movieId,tag,timestamp\\n22,26479,Kevin Kline,1583038886\\n22,79592,misogyny,1581476297\\n22,247150,acrophobia,1622483469\\n34,2174,music,1249808064\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# ml-32m/ratings.csv\n",
    "userId,movieId,rating,timestamp\n",
    "1,17,4.0,944249077\n",
    "1,25,1.0,944250228\n",
    "1,29,2.0,943230976\n",
    "1,30,5.0,944249077\n",
    "# ml-32m/movies.csv\n",
    "movieId,title,genres\n",
    "1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy\n",
    "2,Jumanji (1995),Adventure|Children|Fantasy\n",
    "3,Grumpier Old Men (1995),Comedy|Romance\n",
    "4,Waiting to Exhale (1995),Comedy|Drama|Romance\n",
    "5,Father of the Bride Part II (1995),Comedy\n",
    "# ml-32m/tags.csv\n",
    "userId,movieId,tag,timestamp\n",
    "22,26479,Kevin Kline,1583038886\n",
    "22,79592,misogyny,1581476297\n",
    "22,247150,acrophobia,1622483469\n",
    "34,2174,music,1249808064\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ccfbef",
   "metadata": {},
   "source": [
    "## 基础NCF模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e266b52",
   "metadata": {},
   "source": [
    "#### 导入必要包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2331da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271cb8c",
   "metadata": {},
   "source": [
    "#### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cb6d10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据读取成功\n"
     ]
    }
   ],
   "source": [
    "# 数据预处理\n",
    "ratings = pd.read_csv('../Dataset/ml-32m/ratings.csv')\n",
    "csv_file_path = 'loss_data.csv'\n",
    "print(\"数据读取成功\")\n",
    "# 创建用户和电影映射字典,将稀疏数据稠密化\n",
    "user_ids = ratings['userId'].unique()\n",
    "user_to_idx = {user: idx for idx, user in enumerate(user_ids)}\n",
    "movie_ids = ratings['movieId'].unique()\n",
    "movie_to_idx = {movie: idx for idx, movie in enumerate(movie_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a2ca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为连续索引\n",
    "ratings['user_idx'] = ratings['userId'].map(user_to_idx)\n",
    "ratings['movie_idx'] = ratings['movieId'].map(movie_to_idx)\n",
    "# 归一化评分到0-1范围\n",
    "ratings['rating'] = ratings['rating'] / 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaf291b",
   "metadata": {},
   "source": [
    "#### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7ab3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a6429e",
   "metadata": {},
   "source": [
    "#### 实现Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08fdcffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义Dataset类\n",
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.users[idx], dtype=torch.long),\n",
    "            torch.tensor(self.movies[idx], dtype=torch.long),\n",
    "            torch.tensor(self.ratings[idx], dtype=torch.float)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202d1bb",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d75fff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "batch_size = 2048\n",
    "\n",
    "train_dataset = MovieLensDataset(train_df['user_idx'].values, \n",
    "                               train_df['movie_idx'].values,\n",
    "                               train_df['rating'].values)\n",
    "val_dataset = MovieLensDataset(val_df['user_idx'].values,\n",
    "                             val_df['movie_idx'].values,\n",
    "                             val_df['rating'].values)\n",
    "test_dataset = MovieLensDataset(test_df['user_idx'].values,\n",
    "                              test_df['movie_idx'].values,\n",
    "                              test_df['rating'].values)\n",
    "print(train_dataset[0])  # 打印第一个样本以验证数据集\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,pin_memory=True)\n",
    "print(\"数据加载成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c1ea6",
   "metadata": {},
   "source": [
    "#### 定义推荐模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e6d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义推荐模型\n",
    "class Recommender(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=32, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_emb = nn.Embedding(num_movies, embedding_dim)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2*embedding_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, user, movie):\n",
    "        user_emb = self.user_emb(user)\n",
    "        movie_emb = self.movie_emb(movie)\n",
    "        x = torch.cat([user_emb, movie_emb], dim=1)\n",
    "        return self.fc(x).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54451cfa",
   "metadata": {},
   "source": [
    "#### 加载模型，指定优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a8039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 初始化模型和优化器\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "if(torch.cuda.is_available()):\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"使用GPU加速\")\n",
    "print(device)\n",
    "\n",
    "n_users = len(user_ids)\n",
    "n_movies = len(movie_ids)\n",
    "\n",
    "model = Recommender(n_users, n_movies).to(device)\n",
    "if os.path.exists('best_model.pth'):\n",
    "    model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "    print(\"已加载保存的模型参数\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7f564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "loss_array = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1} Training'):\n",
    "        user, movie, rating = [x.to(device) for x in batch]\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user, movie)\n",
    "        loss = criterion(pred, rating)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * user.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f'Epoch {epoch+1} Validation'):\n",
    "            user, movie, rating = [x.to(device) for x in batch]\n",
    "            pred = model(user, movie)\n",
    "            val_loss += criterion(pred, rating).item() * user.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    loss_array.append([train_loss,val_loss])\n",
    "\n",
    "    print(f'Epoch {epoch+1}:')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    # 保存损失数据到CSV文件\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['train_loss', 'val_loss'])  # 添加表头\n",
    "        csv_writer.writerows(loss_array)\n",
    "\n",
    "print(\"训练完成，开始测试阶段\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1582e321",
   "metadata": {},
   "source": [
    "#### 测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        user, movie, rating = [x.to(device) for x in batch]\n",
    "        pred = model(user, movie)\n",
    "        test_loss += criterion(pred, rating).item() * user.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "test_loss_csv = 'test_loss.csv'\n",
    "\n",
    "with open(test_loss_csv, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['test_loss'])  # 添加表头\n",
    "    csv_writer.writerow([test_loss])  # 写入测试损失\n",
    "\n",
    "print(loss_array)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test RMSE: {np.sqrt(test_loss * 5.0**2):.4f}')  # 反归一化后计算RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf08444",
   "metadata": {},
   "source": [
    "#### 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f23946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import  csv\n",
    "import os\n",
    "# 直接使用当前工作目录\n",
    "csv_path = 'loss_data.csv'\n",
    "\n",
    "# Read train_loss and test_loss from loss_data.csv\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "with open(csv_path, 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        train_loss.append(float(row['train_loss']))\n",
    "        val_loss.append(float(row['val_loss']))\n",
    "\n",
    "# Create epochs array\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8,6))\n",
    "# plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs,[tl* 5.0**2 for tl in train_loss],'p-',label=\"Train RMSE\")\n",
    "\n",
    "# plt.plot(epochs, test_loss, 'r-',label='val Loss')\n",
    "plt.plot(epochs,[tl* 5.0**2 for tl in val_loss],'p-',label=\"Validating RMSE\")\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Training and Validating Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "plt.ylabel(ylabel='RMSE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e02a06",
   "metadata": {},
   "source": [
    "## 添加BERT模块对标题进行编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057edbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8dbb57",
   "metadata": {},
   "source": [
    "#### 添加BERT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8530d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# 加载BERT tokenizer和模型\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "bert_model.eval()  # 推理模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8c5e8f",
   "metadata": {},
   "source": [
    "#### 定义电影名称转BERT向量的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f0d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def title_to_bert_vec(title):\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(title, return_tensors='pt', truncation=True, max_length=16)\n",
    "        outputs = bert_model(**inputs)\n",
    "        # 取[CLS]向量作为整体表示\n",
    "        cls_vec = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "    return cls_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd58252",
   "metadata": {},
   "source": [
    "#### 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38589ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "ratings = pd.read_csv('../Dataset/ml-32m/ratings.csv')\n",
    "csv_file_path = 'loss_data.csv'\n",
    "print(\"数据读取成功\")\n",
    "# 创建用户和电影映射字典,将稀疏数据稠密化\n",
    "user_ids = ratings['userId'].unique()\n",
    "user_to_idx = {user: idx for idx, user in enumerate(user_ids)}\n",
    "movie_ids = ratings['movieId'].unique()\n",
    "movie_to_idx = {movie: idx for idx, movie in enumerate(movie_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6315ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换为连续索引\n",
    "ratings['user_idx'] = ratings['userId'].map(user_to_idx)\n",
    "ratings['movie_idx'] = ratings['movieId'].map(movie_to_idx)\n",
    "# 归一化评分到0-1范围\n",
    "ratings['rating'] = ratings['rating'] / 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed409a1e",
   "metadata": {},
   "source": [
    "#### 生成BERT向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cce04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('../Dataset/ml-32m/movies.csv')\n",
    "movieid2bertvec = {\n",
    "    row['movieId']: title_to_bert_vec(row['title'])\n",
    "    for _, row in movies.iterrows()\n",
    "}\n",
    "bert_dim = next(iter(movieid2bertvec.values())).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15892290",
   "metadata": {},
   "source": [
    "#### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19990504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集划分\n",
    "train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7913138",
   "metadata": {},
   "source": [
    "#### 修改Dataset，返回BERT向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a4efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensDataset(Dataset):\n",
    "    def __init__(self, users, movies, ratings, movie_ids, movieid2bertvec):\n",
    "        self.users = users\n",
    "        self.movies = movies\n",
    "        self.ratings = ratings\n",
    "        self.movie_ids = movie_ids # movie_ids = movie_to_idx\n",
    "        self.movieid2bertvec = movieid2bertvec\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.users)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        movie_id = self.movie_ids[idx]\n",
    "        bert_vec = self.movieid2bertvec[movie_id]\n",
    "        return (\n",
    "            torch.tensor(self.users[idx], dtype=torch.long),\n",
    "            torch.tensor(self.movies[idx], dtype=torch.long),\n",
    "            torch.tensor(self.ratings[idx], dtype=torch.float),\n",
    "            torch.tensor(bert_vec, dtype=torch.float)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d2b8dc",
   "metadata": {},
   "source": [
    "#### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c896bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据加载器\n",
    "batch_size = 2048\n",
    "\n",
    "train_dataset = MovieLensDataset(train_df['user_idx'].values, \n",
    "                               train_df['movie_idx'].values,\n",
    "                               train_df['rating'].values,\n",
    "                               train_df[\"movieId\"].values,\n",
    "                               movieid2bertvec)\n",
    "val_dataset = MovieLensDataset(val_df['user_idx'].values,\n",
    "                             val_df['movie_idx'].values,\n",
    "                             val_df['rating'].values,\n",
    "                             train_df[\"movieId\"].values,\n",
    "                             movieid2bertvec)\n",
    "test_dataset = MovieLensDataset(test_df['user_idx'].values,\n",
    "                              test_df['movie_idx'].values,\n",
    "                              test_df['rating'].values,\n",
    "                              train_df[\"movieId\"].values,\n",
    "                              movieid2bertvec)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size,pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size,pin_memory=True)\n",
    "print(\"数据加载成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2855fe90",
   "metadata": {},
   "source": [
    "#### 定义推荐模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ea8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommender(nn.Module):\n",
    "    def __init__(self, num_users, num_movies, embedding_dim=32, hidden_dim=64, bert_dim=768):\n",
    "        super().__init__()\n",
    "        self.user_emb = nn.Embedding(num_users, embedding_dim)\n",
    "        self.movie_emb = nn.Embedding(num_movies, embedding_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            # 两个emb宽度加上bert_vec的宽度\n",
    "            nn.Linear(2*embedding_dim + bert_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim//2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, user, movie, bert_vec):\n",
    "        user_emb = self.user_emb(user)\n",
    "        movie_emb = self.movie_emb(movie)\n",
    "        x = torch.cat([user_emb, movie_emb, bert_vec], dim=1)\n",
    "        return self.fc(x).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b59a6",
   "metadata": {},
   "source": [
    "#### 加载模型，指定优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 初始化模型和优化器\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "n_users = len(user_ids)\n",
    "n_movies = len(movie_ids)\n",
    "\n",
    "model = Recommender(n_users, n_movies).to(device)\n",
    "if os.path.exists('best_model.pth'):\n",
    "    model.load_state_dict(torch.load('best_model.pth', map_location=device))\n",
    "    print(\"已加载保存的模型参数\")\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7881641",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd943f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "epochs = 50\n",
    "best_val_loss = float('inf')\n",
    "loss_array = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f'Epoch {epoch+1} Training'):\n",
    "        user, movie, rating, bert_vec = [x.to(device) for x in batch]\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(user, movie, bert_vec)\n",
    "        loss = criterion(pred, rating)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * user.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # 验证阶段\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f'Epoch {epoch+1} Validation'):\n",
    "            user, movie, rating = [x.to(device) for x in batch]\n",
    "            pred = model(user, movie)\n",
    "            val_loss += criterion(pred, rating).item() * user.size(0)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    \n",
    "    loss_array.append([train_loss,val_loss])\n",
    "\n",
    "    print(f'Epoch {epoch+1}:')\n",
    "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "    \n",
    "    # 保存最佳模型\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    # 保存损失数据到CSV文件\n",
    "    with open(csv_file_path, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['train_loss', 'val_loss'])  # 添加表头\n",
    "        csv_writer.writerows(loss_array)\n",
    "\n",
    "print(\"训练完成，开始测试阶段\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48596a04",
   "metadata": {},
   "source": [
    "#### 测试阶段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff5194",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc='Testing'):\n",
    "        user, movie, rating, bert_vec = [x.to(device) for x in batch]\n",
    "        pred = model(user, movie, bert_vec)\n",
    "        test_loss += criterion(pred, rating).item() * user.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "test_loss_csv = 'test_loss.csv'\n",
    "\n",
    "with open(test_loss_csv, 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['test_loss'])  # 添加表头\n",
    "    csv_writer.writerow([test_loss])  # 写入测试损失\n",
    "\n",
    "print(loss_array)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "print(f'Test RMSE: {np.sqrt(test_loss * 5.0**2):.4f}')  # 反归一化后计算RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6044f5",
   "metadata": {},
   "source": [
    "#### 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b705af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import  csv\n",
    "import os\n",
    "# 直接使用当前工作目录\n",
    "csv_path = 'loss_data.csv'\n",
    "\n",
    "# Read train_loss and test_loss from loss_data.csv\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "with open(csv_path, 'r', newline='') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        train_loss.append(float(row['train_loss']))\n",
    "        val_loss.append(float(row['val_loss']))\n",
    "\n",
    "# Create epochs array\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8,6))\n",
    "# plt.plot(epochs, train_loss, 'b-', label='Training Loss')\n",
    "plt.plot(epochs,[tl* 5.0**2 for tl in train_loss],'p-',label=\"Train RMSE\")\n",
    "\n",
    "# plt.plot(epochs, test_loss, 'r-',label='val Loss')\n",
    "plt.plot(epochs,[tl* 5.0**2 for tl in val_loss],'p-',label=\"Validating RMSE\")\n",
    "\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Training and Validating Loss Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "plt.ylabel(ylabel='RMSE')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
